\section{Software Design}
\label{sec:softwareDesign}
  Following the design of the mechanical and electrical aspects of the rover was that of the software as hosted by the RCE as well as for user control and interaction. The section covers the design process undertaken before and during the development of the software for all aspects of the project. The software design and development processes were highly iterative as many of the design choices had to be made after realisation of the technology capabilities and conversely, many of the technology choices were made based on what was required on a more functional and detailed level at design time. The two processes are separated as far as possible in this report for a friendlier structure.
  
  The design stage initiated with an overview of the requirements, descriptions of the technologies that were chosen for development and a plan of the designed structures of each of the subsystems as categorised in the overview.
  
  \subsection{Systems Overview in Context}
    An attempt was made to mimic the communications and software structures and patterns used for MSL (and other similar missions) and as such, the software system for this project resembles the three component structure consisting of a system on the rover, the software employed for the collection of relay satellites and ground-based DSN hardware, and the client front-end software as used by the MSL team. Figure~\ref{fig:specs-functionalBreakdown} already highlights the basic breakdown of the software systems. As discussed in Section~\ref{subsubsec:rover-equivalence}, the three major software subsystems by name included the Rover Compute Element (RCE) and the Robot Sequencing and Visualisation Program (RSVP) divided further into the Server and the Client.
    
    The RCE was hosted by the computational hardware on the rover (the Intel Edison board, here-onwards referred to as the RCE board) and required control of hardware, sensory and digital input and communication with the RSVP Server in order to fulfil the end requirements. This imposed the need upon the RCE to be able to read from and control the hardware inputs and outputs on the RCE board. For communication, the RCE was to make use of the on-chip WiFi module to send and receive data which would make up the commands, telemetry and video stream.
    
    The RSVP Server was a standalone server process serving as the middle-man between the RSVP Client and the RCE with respect to telemetry, control and video data. The Server established connections with the RCE for data message and video stream type communications and was required to act as a broadcast node to allow for multiple RSVP Client instances to receive the data messages and the video stream. Details on the network topologies, specifically those of the video broadcasting component, are discussed in the structure plans to follow. The RSVP server also hosted the RSVP Client web application to be served and coordinated control access by the active clients.
    
    The RSVP Client as served by the RSVP Server was a web application which was required to facilitate user input for control of the rover, display the video feed from the RCE as broadcast by the Server as well as provide telemetry received via data messages. As described further in the following design sections, the RSVP Client consisted of a front-end component visible in the browser or any web-view as well as an underlying system managing the flow of data through the application and handling the communication between it and the RSVP Server. State and user input data was to be sent to and received by the Server and the video data received to be displayed in the video element within the interface.

    \begin{figure}[h!]
      \centering
      \includegraphics[width=0.7\linewidth]{figures/softDesign-useOverview}
      \caption[Diagramatic depiction of a typical use scenario of the software system.]{Diagramatic depiction of a typical use scenario of the software system.}
      \label{fig:softDesign-useOverview}
    \end{figure}

    An overview of the entire software system on a very high level is shown in Figure~\ref{fig:softDesign-useOverview}, a typical scenario involving the operational rover, the RSVP server in communication with the RCE and multiple RSVP Clients connected to the Server. The intention was to have the system be capable of allowing multiple devices on the network to connect to and interact with the system and one of the devices to have rover control access. The RSVP Server would manage the connected Clients and decide which of them would be able to control the rover. The principle behind the choice of which Client becomes the controlling Client is discussed later on.
    
  \subsection{Plan of Structure}
    In order to effectively coordinate the design and development of the software system as a whole, structural plans of the system and the subsystems within were constructed. The plans also aided the realisation of requirements and, further, choices of software technologies to use for each of the subsystems and components. The high level structure of the three subsystems and their interconnectedness was designed before constructing more detailed perspectives of each of them.
    
    \subsubsection{System Architectural Structure}            
      Figure~\ref{fig:softDesign-sysArchitectureStructure} is a high-level diagram showing a single-client scenario involving the three primary software subsystems and the means by which they were to communicate and interact. The solid arrows indicate wired connections and these exist on the RCE board for, as on the left, hardware communication and interfacing with sensory devices such as the camera. The RCE uses the wireless module to transmit video data and message data to the Server via the wireless module on the RCE board. The RSVP Server then offers the application source for the RSVP Client to be requested and loaded. Control, telemetry and video data is then sent and received between the RSVP Client and Server.

      \begin{figure}[h!]
        \centering
        \includegraphics[width=1\linewidth]{figures/softDesign-sysArchitectureStructure}
        \caption[Diagram outlining the basic software system component structure.]{Diagram outlining the basic software system component structure.}
        \label{fig:softDesign-sysArchitectureStructure}
      \end{figure}
      
      As mentioned previously, the RSVP Server's primary role was to relay data between the RSVP Client and the RCE. Employing this structure for the flow of data allowed for many RSVP Client instances to exist and interface with the system. Not shown in Figure~\ref{fig:softDesign-sysArchitectureStructure} is the case where there are $N$ RSVP Clients on the network whereby one client would be in control of the rover, using the control, telemetry and video communication channels, and $N-1$ Clients would be receiving telemetry and video data only. Throughout the software design process, as much of the computational burden anticipated to exist in the system was offloaded onto the RSVP Server simply due to the fact that the RCE had the most severe computational performance limitations. The RSVP Server could be scaled to provide any required performance and thus could absorb functional components that were computationally taxing, an example of which is handling a large number of client connections that all require video and telemetry data. Communication specifics between all of the subsystems in Figure~\ref{fig:softDesign-sysArchitectureStructure} will be discussed in the design sections that follow as well as in the development sections.
      
      It can be seen in Figure~\ref{fig:softDesign-sysArchitectureStructure} that data transmission between all components of the system are grouped into two main channels: video data and message data. The separation of the two is made clearer in Section~\ref{subsubsec:rsvpServersPlan} which discusses the broadcast topology intended for use for the video data and how the data and the characteristics of the required communication naturally differ from that of telemetry and control data. Splitting of the two flows of data also allowed for finer control over the transmission in terms of setup sequences and during operation. As such, the message data channel between the Server and a Client was split on the basis of function.
      
  \subsection{Technology Choices}
    \subsubsection{Common Platform Flavour}
      The fact that the RCE board's computer supported the use of Linux as an operating system presented an opportunity to have all aspects of the software system follow suit in this regard, specifically the RSVP Server. The Server was intended to be flexible in form-factor to facilitate the open-sourcing secondary objective of the project and for the purpose of the system developed for this report, it was chosen to be a PC capable of running a distribution of Linux. Most distributions of Linux offer the stability and performance required by server-type processes and applications which explains the popularity of the operating system in network and internet service industries \cite{w3techs_Oct2016} and hence the decision to employ such as the operating system for the Server. The choice between heterogeneous and homogeneous architectures for the software system resolved to a trade-off between the advantage of technological flexibility as in the heterogeneous case and development simplicity in the other. Technological flexibility would have benefited the design in allowing choice of technologies that would better suit each of the subject components, perhaps to optimise resource consumption (storage, computation or even power) or improve compatibility with associated hardware and other components. Due to the limited time-frame of the project as well as there being no specification related to such optimisations, the benefit of the ease of learning and design brought by a homogeneous system weighed in greater than flexibility, together with the abundance of packages and tools available for a Linux-based platform. Using Linux also supported the free, open-source software ideology making it more readily available to those who intend to be involved.
      
      \subheading{JavaScript}\\\\
        With both the RCE and RSVP Server being based on a Linux platform as well as the RSVP Client being web-based (discussed further in Section~\ref{subsubsec:applicationFrontend}), another opportunity to employ a common technology across the system was presented, specifically the use of the JavaScript language most commonly associated with websites and web applications. Using JavaScript across the stack (including the RCE) followed the architecture pattern of homogeneity, simplified the learning process before and during development of the subsystems and minimised anticipated development overhead in terms of software development environments and build tools. Using JavaScript kept the project on a modern, popular and cutting-edge trajectory, a choice backed by it being a widely recognised full-stack solution used for services such as Netflix, Paypal, Medium, Uber, Twitter and Airbnb \cite{nodeusers_2016} \cite{driesbuytaert_2016}. JavaScript's place in an embedded context was found to be increasingly fitting, especially in scenarios where an internet-connected stack could benefit from the seamlessness of technologies as a result. Given that the Intel Edison was a device which comfortably bridged between a embedded environment dedicated to hardware alone and a connected computer with no direct hardware-interface relevance at all, JavaScript provided a good balance between the two areas of software and kept available interoperability with software and tools that could cover the extremes if required. Other benefits include the use of JSON as a well recognised data format, untyped syntax and the semantic depth provided by the object-oriented nature of the language.
        
        JavaScript itself was not the platform choice in entirety and due to the fact that it is an interpreted language, the project required a choice of runtime environment that would be able to be used on both the RCE and the RSVP server. It was found that the most popular server-side runtime for JavaScript projects was Node.js, an asynchronous, event driven, single thread environment that utilises the V8 JavaScript Engine. It was identified that the structure of the stack of this project resembled a typical IoT stack (involving a front-end, back-end and connected devices) and Node.js was the most popular environment for applications that required real-time data synchronisation and connectivity between devices with a growth in usage unlike any other JavaScript runtime or framework \cite{nodejsSurvey_2016}.
        
        \begin{figure}[h!]
          \centering
          \includegraphics[width=0.8\linewidth]{figures/softDesign-nodeEventLoop}
          \caption[Diagram showing the Node.js architecture's event-loop execution design.]{Diagram showing the Node.js architecture's event-loop execution design (adapted from \cite{fig:softDesign-nodeEventLoop_cite1} and \cite{fig:softDesign-nodeEventLoop_cite2}).}
          \label{fig:softDesign-nodeEventLoop}
        \end{figure}
        
        A key advantage of the way in which Node.js runs is in the event loop architecture that it utilises, as demonstrated in Figure~\ref{fig:softDesign-nodeEventLoop}. Since Node.js is single threaded, in order to bring asynchronism to an application, at least one point of the software architecture should be sequential in execution, taken care of in the Node.js case with its event loop. The significance of this method of execution is in the advantages that it brings when dealing with operations that block the execution flow. In the context of server applications where requests are fully asynchronous, any operation that blocks handling of such requests will result in poor response performance and a poor end user experience. System operations are normally always blocking in operation and thus Node.js utilises a system library \mintinline{js}{libuv} to offload the blocking calls to system threads, the important point here being that the event loop need not wait for the operation to complete. This means that the left hand side of the flow of execution in Figure~\ref{fig:softDesign-nodeEventLoop} (application requests) is scalable with minimised performance cost, allowing many end users to be connected to and request data from the server at any given time.
        
        Node.js brought with it open-source resources, tools and software modules which greatly improved the development time and opened up what was possible from the perspective of both the RCE and the RSVP Server (and Client, but to a lesser extent). Many of the open-source projects used throughout the software system were chosen during development based on demand and are mentioned in-text in the design and development sections as well as in Appendix~\ref{appendix:openSourceList}. % TODO: List the open source dependencies
        
        A project worthy of mentioning at this point is one that was in development at the time of writing by NASA, namely Open MCT\footnote{Open MCT: \url{https://nasa.github.io/openmct/}}, a web-based mission control framework utilising Node.js as the server runtime (although the architecture design was intended to be server-agnostic). Open MCT was a great example of how an across-the-stack JavaScript implementation is well suited to a data and communication critical application. Another example of Node.js's place in the aerospace industry was the use of it by United Technologies Corporation Aerospace Systems (UTCAS) to develop a data management system for the lifecycle of EVA spacesuits, a response to a problem identified in the analysis of data which was before hosted across separate and legacy databases \cite{nodejsSpaceSuit_2016}.        
        
      \subheading{ECMAScript 6}\\\\
        Announced on the 6th of June 2015, the Sixth Edition of JavaScript, also known as ECMAScript 6 (ES6), introduced a significant range of new features to the language many of which are syntactically unique. It was decided that the project make use of the new edition in order to remain in-sync with modern modules and technologies at the time. In fact, a few features from the Seventh Edition (ES7, released on the 7th of June 2016) were included as well, both additions to the original ES5 and ES5.1 resulting in an added complexity in the build process. The changes to the build process are dealt with in the development section.
        
    \subsubsection{Embedded Software Platform}
      The RCE board's Intel Edison computer ran a default operating system: a custom version of Linux from the Yocto Linux Project maintained and compiled by Intel. The open-source Yocto Project provides the tools and resources to build Linux distributions specifically for embedded targets. Intel's distribution was a modified version of ``Yocto Poky'' and could be flashed onto the Intel Edison using the tools provided. After little experimentation with the distribution, it was found that many of the niceties of a Debian-based operating system were not present, the main issue being the lack of the package manager (\mintinline{js}{apt-get}) and its associated online repositories which would aid the development process. For this reason, a different distribution was chosen for the RCE, ``Ubilinux'', a customised version of ``Debian Wheezy'' which was maintained by Emutex. It was decided that due to mid-project termination of support for Ubilinux from Emutex, Ubilinux would remain the distribution used during development of the rover after which it would be replaced with the latest version of Yocto Poky if time permitted. This would provide an opportunity to build into the distribution the tools confirmed as being required for the operation of the RCE.
    
      Since it is primarily a server runtime, Node.js itself did not have native support for embedded hardware control such as that required for the RCE. It was important to first understand how the hardware was interfaced with from the perspective of the Linux user space\footnote{Linux user space: memory area and separation of execution reserved for application code and some hardware drivers, which sits separate from the kernel space reserved for low level code and drivers} on the Intel Edison. One of the base-level principles around which Linux was developed is the concept of the hierarchical file-system. Most importantly, the file-system need not necessarily consist of files that represent viewable and editable data in the user-owned sense (documents, pictures and other media, for example) but also files that hold system data which have been allowed to propagate from the kernel space to the user space. The system files may represent various hardware components and subsystems, holding state information and allowing control of the hardware through editing of the associated files. The significance of this concept is that the Intel Edison exposes hardware pin access using a virtual file system from the kernel upwards into the user space using \mintinline{js}{sysfs}. When the \mintinline{js}{sysfs} file system is mounted, files organised and structured to represent the GPIOs and other hardware peripherals appear in the user space file hierarchy and if the user has the required permissions, it can read from and write to the files from software. A diagram showing the components of this type of hardware interface on the Intel Edison is shown in Figure~\ref{fig:softDesign-sysfsExample}.
      
      \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\linewidth]{figures/softDesign-sysfsExample}
        \caption[Simplified diagram showing the interface between peripheral hardware and code running in the Linux user space.]{Simplified diagram showing the interface between peripheral hardware and code running in the Linux user space (adapted from \cite{fig:softDesign-sysfsExample_cite1} and \cite{fig:softDesign-sysfsExample_cite2}).}
        \label{fig:softDesign-sysfsExample}
      \end{figure}
      
      Atop this method of hardware interface was another abstraction that was available: a C/C++ library, called \mintinline{js}{mraa}, which provided common \mintinline{js}{sysfs} file operations in code allowing for better semantics amongst the large amount of multiplexing required on the Intel Edison board. \mintinline{js}{mraa} also provided JavaScript bindings so that the library could be easily utilised in the RCE software subsystem running in the Node.js environment. This was not the end of the stack, however, as multiple Node.js modules were available that resided atop the JavaScript abstraction of \mintinline{js}{mraa}. Up until this point, little variation in the platform layers was available and this final choice of module formed the primary design choice for the RCE platform. Two robotics framework modules were chosen as candidates based on popularity and compatibility with the Intel Edison (and the Arduino Breakout Expansion), namely ``Johnny-five'' and ``Cylon.js''. Both modules leveraged the object-oriented nature of JavaScript to provide easy interface with the hardware on the RCE board as well as provide the ability to remotely program and command the device on the same network. The architectures of each of the modules were compared and it was found that Cylon.js emphasised the remote scripted topology compared to code that would run local to the device to be controlled. The intention was to have the RCE be independent in operation from any other device (i.e. not be strictly reliant on another device to be online) much like the autonomy of \textit{Curiosity} and therefore Johnny-five (hereafter referred to as J5) was chosen as the framework to use. An example snippet of how one would use J5 is shown in Snippet~\ref{code:softDesign-j5ExampleLed}.
      
      \begin{code}
        \begin{minted}{js}
          import * as five from 'johnny-five',
          
          // Create the board instance
          board = new five.Board();
          
          // Setup listener to wait for board to become ready
          board.on('ready', () => {
            // Create an Led on pin 13
            var led = new five.Led(13);
          
            // Strobe the pin on/off, defaults to 100ms phases
            led.strobe();
          });
        \end{minted}
        \caption{Example initialisation of a device and an LED in J5.}
        \label{code:softDesign-j5ExampleLed}
      \end{code}
      
      \begin{figure}[h!]
        \centering
        \includegraphics[width=0.5\linewidth]{figures/softDesign-rceHardwarePlatformStack}
        \caption[Diagram of the hardware stack designed for the RCE.]{Diagram of the hardware stack designed for the RCE.}
        \label{fig:softDesign-rceHardwarePlatformStack}
      \end{figure}
      
      The resulting RCE hardware stack is shown in Figure~\ref{fig:softDesign-rceHardwarePlatformStack} which allowed hardware exposure to the RCE software for all the specified requirements, except the camera, which was handled in a lower-level manner discussed in the development section. A further addition to the stack, \mintinline{js}{edison-io}, is shown in the diagram, which is responsible for dealing with hardware platform specifics in an attempt to keep Johnny-Five and its class and driver implementations as consistent and standard as possible. The \mintinline{js}{edison-io} project is a direct wrapper of \mintinline{js}{galileo-io}, a board support module compatible with the Intel Edison.
      
    \subsubsection{The Web as an Application Front-end}
    \label{subsubsec:applicationFrontend}
      Up until this point, the RSVP Client has been said to be a web application without proper reasoning. The decision was made at the start of the project not without consideration of other front-end platforms. Whilst not explicitly stated in the project specifications, the intention behind the RSVP Client was for it to be a highly accessible application that need not be restricted to within the exhibition space. This follows the theme of the project being targeted at educational environments and general outreach where an application that can be accessed from multiple different devices in multiple locations would prove to be a valuable feature.
      
      The two main categories exist with respect to base-level technologies for the front-end, native applications and web applications, where native refers to applications that are dedicated to the subject device or platform. Investigations made into the popularity of the two application types \cite{jeffSmith_2016}\cite{samShabaan_2016} suggested that at the time of decision, native applications were more commonly used but most likely for specific and repeated tasks or where CPU-intensive computations are required. What was also found, albeit a trivial point, was that the development time, complexity of projects and increased maintenance and skills is required for applications that are to be natively developed but also available across many different types of devices. The web, however, could be considered a universal platform which attempts to bring platform-agnosticism to web content through browsers. The browser can be seen as a technological buffer between the page content and the hardware on which the browser is running.
      
      The project aimed to have the RSVP Client be an application that could be run on as many devices as possible, varying in operating systems, form factors and screen sizes. This objective coupled with the very short development time-frame gave the decision to make the Client a web-based application satisfactory justification. It was also deemed reasonable to make use of the already existing requirement for network-based data communications for the application itself.
      
    \subsubsection{Front-end Framework}
      The RSVP Client could have been developed from first principles or by making use of an already developed front-end JavaScript web-application framework, of which there were an abundance. Many of the frameworks available were created with both user-interface (UI) components and application mechanics in mind. For brevity, a comparison of the candidate frameworks is not shown, however the ones that were considered include AngularJS\footnote{AngularJS: a framework which allows the extension of plain HTML with in-browser JavaScript dependency injection - \url{https://github.com/angular/angular.js}}, ReactJS\footnote{ReactJS: a Facebook developed declarative JavaScript library with a distinct DOM creation and management flow - \url{https://github.com/facebook/react}} and Polymer\footnote{Polymer: a Google developed library come ecosystem which allows the creation of reusable HTML elements with style and functional encapsulation with emphasis on making close use of web standards - \url{https://github.com/Polymer/polymer}}. The chosen framework was Polymer for the following reasons:
      \begin{itemize}
        \item \textbf{Web-components:} Polymer makes heavy use of a particular area of the modern day web standard, the features relating to web components. Web-components allow the encapsulation of functions, features and UI artefacts to result in a component that is re-usable and maintenance-sane. This allows the developer to bring semantic structure to the application in a way which promotes understanding for people who wish to contribute to the project, for example.
        \item \textbf{Shadow-DOM:} Included in the principle of web-components is the Shadow-DOM feature, a mechanism of HTML encapsulation which includes style and associated methods and properties.
        \item \textbf{Declarative Data:} Polymer comes with a rich data management mechanism allowing for the declarative construction of data flow through the application, an area of application design that can get complex and difficult to scale.
        \item \textbf{Polymer Elements Catalog:} Google have provided a large catalog of ready-made Polymer elements which are commonly required UI and application components for easy development. In addition to the Polymer Catalog are elements that have been developed by third parties and made available for use in an open-source manner.
      \end{itemize}
      
      The Polymer Project had also made indications towards making the framework ES6 compliant meaning the framework would remain a sustainable choice for the RSVP Client application.
      
    \subsubsection{Message Data Communication}
      Message data communication was required between the RCE and RSVP Server as well as between the RSVP Server and the RSVP Client. This data would be a structured payload which in JavaScript amounts to a JSON (JavaScript Object Notation) object, an example of which is shown in Snippet~\ref{code:softDesign-structuredDataExample}. The JSON object can be serialised to a string which, in fact, becomes irrelevant from an implementation perspective in the context of the chosen technology. This could have been achieved by leveraging the AJAX principle whereby HTTP \mintinline{js}{POST}s and \mintinline{js}{GET}s are made from a client endpoint to a server endpoint. In the case of an HTTP \mintinline{js}{POST}, the receiving endpoint may accept the transaction and do with the data what it requires. A \mintinline{js}{GET} required the receiving endpoint to send a response back, hence giving AJAX bidirectional capabilities. A big driver behind the adoption of AJAX was the fact that web pages did not have to refresh the browser window to make such a request and thus various parts of the page could update in a manner more similar to an application. This is referred to as a Single Page Application (SPA).
      
      \begin{code}
        \begin{minted}{js}
          {
            name: 'Message Name',
            type: 'data',
            payload: {
              key1: 'data1',
              key2: ['data2', 'data3'],
            },
          }
        \end{minted}
        \caption{An example of a structured data message.}
        \label{code:softDesign-structuredDataExample}
      \end{code}
      
      However, data was required to be pushed from both endpoints, regardless of whether or not the endpoint was a ``server'' and AJAX did not provide such connection persistence. A technique called long-polling\footnote{Long-polling: a method by which an HTTP connection is kept open until data is ready to be pushed as a response} was a popular progression from AJAX, however, a more efficient method was available. A new communication protocol was introduced in 2008 called WebSocket which combined a small portion of the HTTP protocol, specifically the initial handshake, with the use of a TCP connection to provide full duplex communication with no regressions in security \cite{websocket_2016}. To open a WebSocket connection, an ordinary HTTP \mintinline{js}{GET} request is sent to a server which is ready to receive WebSocket requests, with an additional header \mintinline{html}{Upgrade: WebSocket}. The server then responds to the request and a TCP connection is set up between the two endpoint along which asynchronous, size-unrestricted messages can be sent in both directions without the overhead that HTTP requests incur. As such, this protocol was chosen as frequent and variable sized data messages were required to be sent for telemetry and control purposes.
      
      The WebSocket API was available to use to implement such connections, however, a higher level Node.js module was also available, a widely used abstraction called Socket.io\footnote{Socket.io - \url{https://github.com/socketio/socket.io}}. the benefits of using Socket.io included its simplified API which was kept flush with ES6 as well as the fact that it provided cross-browser fall-backs, offloading the responsibility of ensuring compatibility with different browser vendors onto the Socket.io project. The event-driven nature of the module provided the ability to react to the asynchronous pushing of data as well as event such as new connections and changes in connection status, allowing better control of the communications.
      
      % TODO: Add something about the security
      
    \subsubsection{Media Streaming}
      One of the key requirements for the project was the streaming of a video feed from the rover to the connected Clients over the wireless connection. As discussed in the conceptual development sections, a USB compatible webcam was chosen to capture video from the rover head and provide this data to the RCE board and hence the Linux operating system. It was at this point that a method of streaming the video to the connected Clients was required and the process involved investigating a combination of broadcast topologies and tools that made the various topologies possible.
      
      With the presence of the Server, already responsible for broadcasting telemetry data and relaying control data, video stream broadcasting to the multiple Clients was delegated to it as part of the attempt to offload as much of the computationally and resource intensive operations onto it as possible. This choice of broadcasting meant that, by some means, the RCE would have to send the video data obtained from the webcam to the server over the wireless network connection.
      
      To initiate the process of choosing streaming technologies, research was conducted into popular and effective software tools for streaming video data, specifically for the chosen platform for the RCE and the RSVP Server, Node.js. A common design pattern among many IoT and modern embedded software developers was to use the same technology employed for the transmission of telemetry and control data, Socket.io. Since WebSocket, and hence Socket.io, uses a TCP connection, the size of the transmission data was not a limitation and this made sending large collections of video data possible. The RCE would send the video data frame-by-frame, as separate Socket.io messages, to the RSVP Server, which would simply relay the frames to each of the connected RSVP Clients in the same manner and the frames would then be played back to the user in the application front-end. However, the RCE would still require the video frames to be available as images in a supported format, and due to the fact that the webcam was chosen to be UVC-compatible (i.e. not requiring drivers for operation and control), multiple Node.js modules were available to obtain the video data from it without the need for proprietary software. Some of the modules included \mintinline{js}{v4l2camera}\footnote{\mintinline{js}{v4l2camera} - \url{https://github.com/bellbind/node-v4l2camera}}, \mintinline{js}{linuxcam}\footnote{\mintinline{js}{linuxcam} - \url{https://github.com/Qualphey/node-linuxcam}} and \mintinline{js}{uvc-control}\footnote{\mintinline{js}{uvc-control}: only capable of utilising UVC commands, cannot actually capture video data - \url{https://www.npmjs.com/package/uvc-control}}. Figure~\ref{fig:softDesign-socketVideoStreaming} shows this method of video broadcast in a server to single client example (the example can be extended to having multiple RSVP Client instances all receiving frames from the server with no change).
      
      \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\linewidth]{figures/softDesign-socketVideoStreaming}
        \caption[Diagram of the typical flow of data using Socket.io to stream a video feed.]{Diagram of the typical flow of data using Socket.io to stream a video feed.}
        \label{fig:softDesign-socketVideoStreaming}
      \end{figure}
      
      Further research revealed a second streaming candidate, WebRTC, a technical specification and an open-source project comprising of APIs that can be used to implement Real Time Communications (RTC) on mobile devices and in the browser. Web-based services such as Skype, Discord, Google Hangouts and more use WebRTC for the multimedia streaming components of the applications since it provides a range of features designed a developed towards ensuring a stable communication experience despite a potentially intermittent and unreliable network connection. An important aspect of WebRTC was the fact that the API is a part of the HTML5 specification meaning cross-browser support is driven by competition of compatibility among browser vendors, a valuable dynamic for accessibility for the project. Having said that, WebRTC have provided yet another module, \mintinline{js}{webrtc-adapter}\footnote{\mintinline{js}{webrtc-adapter} - \url{https://github.com/webrtc/adapter/}} to ensure compatibility of applications in the context of a highly volatile platform environment.
      
      In the case of the WebSocket connection technique, it is apparent that there is little to no dynamically optimised transmission of video data at any point in the transport layer meaning the video feed would have been susceptible to poor network performance resulting in severe latency and potential memory issues due to bottlenecks at the sending nodes (RCE and RSVP Server). The desired robustness would have to be developed around the use of Socket.io, a task requiring extra research and development. On the other hand, the WebRTC communications architecture, which can be seen in Figure~\ref{fig:softDesign-webRTCArch}, included a video engine as part of a rich audio-visual enhancement layer which aimed to, among other objectives, protect the stream from transmission issues. As such, WebRTC was chosen as the streaming technique and the benefits that it provided to the project will become apparent in the description below and further in the design sections.
      
      \begin{figure}[h!]
        \centering
        \includegraphics[width=0.8\linewidth]{figures/softDesign-webRTCArch}
        \caption[Diagram of the WebRTC architecture highlighting the video component of the streaming WebRTC provides.]{Diagram of the WebRTC architecture highlighting the video component of the streaming WebRTC provides (adapted from \cite{fig:softDesign-webRTCArch_cite}).}
        \label{fig:softDesign-webRTCArch}
      \end{figure}
      
      As shown in Figure~\ref{fig:softDesign-webRTCArch}, WebRTC caters for both video and audio streaming, however, only the video capabilities apply to this project. In fact, WebRTC provides arbitrary data streaming by means of an \mintinline{js}{RTCDataChannel} as well and this feature was considered for the control and telemetry message data transmission. The choice remained with WebSockets due to the simplicity of the Socket.io API and the benefits that it brought considering its suitability for the associated data type and structure. The principle of operation behind WebRTC is primarily defined by the notion of the manifestation of a session between two peers by means of the \mintinline{js}{RTCPeerConnection} component. The session can be referred to as a call, and the call handshake process involves the two peers that intend to connect and a third element, a signalling server, which facilitates the initial inter-peer communication before the session is live. A more thorough description of the negotiation flow involved in using WebRTC is given in Section~\ref{sec:softwareDesign}. The important point here, however, is the fact that the session is peer-to-peer, meaning video streaming from the rover to the RSVP Client need not involve an intermediate server component at all, apart from the signalling required at session initiation. Whilst this was appealing from the perspective of a simpler network configuration as well as a simpler server design, the project required one-to-many communication since the video streaming was a broadcast as opposed to a two-endpoint call. Having the $N$ number of connected RSVP Clients imposing the responsibility of broadcasting the video onto the RCE would not have been suitable given the resource and computational limitations of the Intel Edison. A preferred configuration was to have the RCE transmit the video data to the RSVP Server and have the Server be responsible for the broadcast of the data. The two configurations are contrasted in Figure~\ref{fig:softDesign-webRTCBroadcastExamples}.
      
      \begin{figure}[h!]
      \centering
      \subfloat[Without intermediate server for video streaming (strictly peer-to-peer).]{
        \includegraphics[width=0.49\linewidth]{figures/softDesign-webRTCBroadcastP2PExample.pdf}
      }%
      \subfloat[With intermediate server for video streaming\label{fig:softDesign-webRTCBroadcastExamples-b}.]{
        \includegraphics[width=0.49\linewidth]{figures/softDesign-webRTCBroadcastServerExample.pdf}
      }
      \caption[Simplified diagrams of typical WebRTC connection configurations.]{Simplified diagrams of typical WebRTC connection configurations.}
      \label{fig:softDesign-webRTCBroadcastExamples}
      \end{figure}
      
      As with the Socket.io abstraction for WebSockets, multiple services and modules were available for the implementation of a WebRTC communication system, all of which were free and consumed much of the work that would have been required for development consisting primarily of boilerplate software. The projects/modules considered included EasyRTC\footnote{EasyRTC: A comprehensive JavaScript library consisting of client and server APIs developed for multiple browsers, Node.js and signalling via Socket.io - \url{https://github.com/priologic/easyrtc}}, SimpleWebRTC\footnote{SimpleWebRTC: A simplified abstraction of the core WebRTC components and features - \url{https://github.com/andyet/SimpleWebRTC}}, Kurento\footnote{Kurento: A WebRTC media server and client APIs offering full media broadcast in multiple configurations - \url{http://www.kurento.org/}} and PeerJS\footnote{PeerJS: A browser-based WebRTC wrapper providing configurable peer-to-peer connections for arbitrary data transfer - \url{http://peerjs.com/}}. PeerJS was not suitable for the streaming-type communication required for the project and SimpleWebRTC and EasyRTC did not provide the richer media server capabilities that Kurento offered. Therefore, Kurento was chosen for the media server it included as well as the fact that it provided server-side APIs developed for Node.js together with client APIs. The Kurento media server was designed to be a common node in a broadcast network and thus suited well the use case of the project.
      
      Detailed design of the system with the implementation of Kurento's media server will be covered in the design and development sections to follow.
  \subsection{Subsystem Design}
    With the primary technology choices made, all three of the software system components were designed in a functional sense, removed as far as possible from implementation and code detail. For brevity, the design (and development) descriptions that follow are written in ``as-built'' style with little reference to many of the design iterations and variety of design choices made along the way. Multiple solutions to a particular aspect or component design problem are discussed where significant.
        
    \subsubsection{RCE Design}
    \label{subsubsec:softDesign-rceDesign}
      \subheading{Plan of Structure}\\\\
        The RCE was a multi-functional, multi-faceted software component bridging the largest gap between hardware control and communications compared to the other two components in the project. It was broken down on the basis of function and each of the subcomponents designed and developed. Multiple main functional areas were identified to be:
        
        \begin{itemize}
          \item \textbf{Control:} Interpretation of incoming control signals and commands, translation of such commands into hardware signals against time and control of RCE board outputs as part of a hardware-to-software abstraction layer. The control subcomponent included initialisation of hardware.
          \item \textbf{Sensing and Telemetry:} Interpretation of incoming hardware signals from sensors and translation of such signals into telemetry messages to be sent to the RSVP Server, including retrieving and packaging of system and hardware state telemetry data.
          \item \textbf{Communication:} A transport layer providing a means of communication with the RSVP Server for telemetry, control and video data transmission.
          \item \textbf{System Operation:} Initialisation of the RCE system as a whole including the execution of predefined system sequences.
        \end{itemize}
        
        Figure~\ref{fig:softDesign-rceStructurePlan}, an overall block diagram of the designed RCE structure, shows briefly the presence of the identified functional areas and how they interrelate. The RCE was ultimately governed by the Node.js application entry point and system sequences (not to be confused with RSVP control sequences). System sequences could be executed at any point during the RCE lifetime and were responsible for coordination of initialisations of hardware and software components as well as performing routines during operation. Routines included system vitality checks, routine maintenance or emergency shutdown procedures. The system sequencing mechanism allowed sequences to be executed synchronously or be driven by events (asynchronous) and allowed for pluggable and scalable sets of sequences with very little resultant impact on the general operation of the RCE. Importantly, sequences at this level were designed to only be responsible for system functions and operations and not any aspect of hardware control.
        
        \begin{figure}[h!]
          \centering
          \includegraphics[width=1\linewidth]{figures/softDesign-rceStructurePlan}
          \caption[Block diagram of the designed software structure for the RCE.]{Block diagram of the designed software structure for the RCE.}
          \label{fig:softDesign-rceStructurePlan}
        \end{figure}
        
        The communication transport layer provided the facilities for communication with the RSVP Server. Attached to the RCE's network I/O were three server components, an HTTP server for pre-WebSocket communication and simple requests, the WebSocket server, named the ``RCEIO'', and a video stream endpoint which was made separate due to the choice of streaming technology. Interface with the hardware components as shown in Figure~\ref{fig:softDesign-rceStructurePlan}, the camera, servos, proximity sensors and voltage input, was taken care of by the control layer, a complex subcomponent involving decoding and translation from incoming commands and signals from the RCEIO translator, a control loop acting as a filter of driving input signals from the translator and finally a hardware abstraction which partially incorporated the Johnny-Five library module.
        
        Most of the above subcomponents were exposed to the data store facility as a means of communicating cross-block and cross-module as well as providing data for telemetry purposes. The reasoning behind the data store as well as its functional design are discussed as part of Section~\ref{subsec:commonSoftwareComponentDesign}.
        
        \subheading{System Sequencing}\\\\
          The pluggable sequencing module is better depicted in Figure~\ref{fig:softDesign-rceSystemSequencingDesign}. Multiple sequences were designed and written to be included in the sequence library and could be called at any point during execution. Sequence operations could have been blocking in execution thus ensuring a deterministic flow of operations or asynchronous if event-driven logic and state-dependency was required. The sequence was exposed to any operation or data that was made importable in JavaScript terms throughout the project.
          
          \begin{figure}[h!]
            \centering
            \includegraphics[width=0.9\linewidth]{figures/softDesign-rceSystemSequencingDesign}
            \caption[Diagram showing the functional design of the RCE's sequencing module.]{Diagram showing the functional design of the RCE's sequencing module.}
            \label{fig:softDesign-rceSystemSequencingDesign}
          \end{figure}
          
          \begin{figure}[h!]
            \centering
            \includegraphics[width=0.7\linewidth]{figures/softDesign-startupSequenceFlow}
            \caption[Sequential flow diagram of the designed startup sequence.]{Sequential flow diagram of the designed startup sequence.}
            \label{fig:softDesign-startupSequenceFlow}
          \end{figure}          
          
          An example sequence that was designed was the startup sequence, the very first set of operations that are executed when the RCE process is invoked on power up of the RCE board (and the rover itself). Figure~\ref{fig:softDesign-startupSequenceFlow} shows the execution flow of the sequence, which began with the initialisation of core system features including instantiation of Linux process monitors and registering the shutdown sequence to process events that indicated a termination of the RCE. The HTTP and RCEIO servers were then created and started after which the sequence waited for a successful incoming connection, from the RSVP Server, by means of the \mintinline{js}{connected} event emitted by the Socket.io instance itself. Upon successful connection, the Johnny-Five board instance was created, an asynchronous operation whereby the sequence resumed in the associated callback method. The rest of the sequence was strictly sequential, including initialisation of all the hardware subcomponents (with prevention against duplicating initialisations/instances), synchronisation of data stores between the RCE's store and the RSVP Server and starting the state driver loop as part of the control aspect of the RCE.
                    
          For the purpose of this project, the following sequences were designed and implemented:
          \begin{itemize}
            \item \textbf{Startup Sequence:} As described above, the startup sequence initialised the system and hardware modules upon power up of the rover.
            \item \textbf{Power Down Sequence:} The power down sequence was triggered upon the termination of the Node.js RCE process which may have been brought about intentionally or in error. Regardless, the sequence ensures that hardware systems are correctly shut down and that communications with the RSVP Server are closed gracefully. 
            \item \textbf{Self-diagnostics Sequence:} The self-diagnostics sequence was designed to be a proof of concept for the level of automation such a rover might have and included testing of all the hardware and software components, reporting back to the RSVP Client the results of the tests. It remained a proof of concept due to the lack of sensory feedback present in the design of the rover and thus the inability of the RCE to make an assessment of a particular component's state of health.
            \item \textbf{Emergency Shutdown Sequence:} The emergency shutdown sequence aimed to replicate the similar sequence on \textit{Curiosity}, designed to handle bringing the rover into a safe state in the event of a detected failure in any aspect of the rover.
          \end{itemize}
          
        \subheading{Hardware Abstraction}\\\\
          Figure~\ref{fig:softDesign-rceStructurePlan} shows the control layer as being a collection of modules allowing commands from the communication layer to be passed through abstractions and translations to result in driving signals sent to the various hardware components. The required signals at the end of the control pipeline were abstracted so as to provide an easier design platform upon which the command translation and execution could be based. Two elements of abstraction were included at the end of the pipeline, one of them being that which was provided by the Johnny-Five framework for all hardware control except the camera. The principle behind Johnny-Five includes hardware components in the form of classes which are instantiated alongside a single \mintinline{js}{Board} instance often referred to as the ``Control System''. Each of the components utilise a ``Controller'' which describes the translation required from the API provided by the component to the peripheral hardware. The second layer of abstraction was custom designed to raise the level of control even further, allowing a more understandable interoperation between it and the rest of the RCE. The second level also consumed configuration and platform specific details and features with respect to the rover hardware and software design (i.e. it was not developed to be scalable or reusable). The structure of this abstraction is shown in Figure~\ref{fig:softDesign-hardwareAbstractionStructure}, beginning with the \mintinline{js}{Board} instance. Each of the second layer abstraction APIs contained an initialisation operation which could be executed from the startup system sequence, as well as multiple hardware specific operations as described in Section~\ref{sec:softwareDevelopment}.
          
          \begin{figure}[h!]
            \centering
            \includegraphics[width=0.7\linewidth]{figures/softDesign-hardwareAbstractionStructure}
            \caption[Diagram showing the structure of the two layered harware abstraction.]{Diagram showing the structure of the two layered harware abstraction.}
            \label{fig:softDesign-hardwareAbstractionStructure}
          \end{figure}
          
        \subheading{Command Structure and Design}\\\\
          An internal command execution system was designed for the RCE to cater for the large number of components that could be controlled as well as to provide a clean and semantically understandable method of control for the user. The command system also aimed to be similar to the command system employed for the control of \textit{Curiosity} (and other such rovers that utilised the RSVP) so that the control interface could be accurately portrayed. The system was designed for both interactive and RoSE style control modes as will be discussed after this sub-section.
          
          The two primary features intended to be controlled through the use of commands was the traversal of the rover and the movement of the camera, both of which involved the servo motors used for their actuation. These two control subjects were prioritised over commands relating to secondary components and operations. Regardless of the subject, however, all commands were classified as either being low level commands to effect a single change on one hardware feature, high level commands which may involve controlling more than one component at one time, and macros which contained a sequence of operations which could either be high or low in level. The macro was then to be decoded into the respective high and low level commands and inserted into the sequence, or executed as a sequence itself.
          
          The user may construct a sequence of commands of all types on the RSVP Client application and transmit the sequence to the RCE (via the Server) which would then be processed and executed, as described further. Therefore, the command shape and the details within were required to be human understandable and human constructable. Figure~\ref{fig:softDesign-cmdStructureDesign} shows the template composition of commands of each level of complexity and the inheritance of common fields by each of the types.
          
          \begin{figure}[h!]
            \centering
            \includegraphics[width=0.65\linewidth]{figures/softDesign-cmdStructureDesign}
            \caption[Diagram showing the types of commands, their object inheritance and macro decoding.]{Diagram showing the types of commands, their object inheritance and macro decoding.}
            \label{fig:softDesign-cmdStructureDesign}
          \end{figure}
          
        
        \subheading{Command Translation and Execution}\\\\
          The two types of user control, interactive control and RoSE control, required to some extent separate command pipelines in that the data acquired from input elements a part of the RSVP Client application differed in shape and frequency. However, due to the command system design, both forms of control were processed to eventually comply with the standard execution process which allowed for the differing pipelines to merge for the majority of the system. More specifically, the point at which the pipelines merged required the input commands or signals to be in the form of high or low level commands with their parameters fully completed, which can be seen in Figure~\ref{fig:softDesign-cmdTranslationFlow}.
          
          \begin{figure}[h!]
            \centering
            \includegraphics[width=1\linewidth]{figures/softDesign-cmdTranslationFlow}
            \caption[Diagram showing the flow of commands through translation and execution operations.]{Diagram showing the flow of commands through translation and execution operations.}
            \label{fig:softDesign-cmdTranslationFlow}
          \end{figure}
          
          Beginning with the interactive type control, the signals received from the RSVP Client described the user's input with respect to the controller as part of the front-end interface. For each of the controllers, a manipulation relay was designed to convert the signals into equivalent commands analogous to a mapping of the controller to the command it represented. For example, rotating the traversal joystick forward was mapped to creating a ``drive'' command with a forwards velocity and no steering of the wheels. The result was a high or low level command which reached the command translator to be further processed. For the RoSE control style, the user composes a sequence of commands and when transmitted to the RCE, is passed through the command decoder which takes macros present in the input array and constructs the equivalent sequence of high and low level commands. The command sequencer handles dispatching the sequence of commands in coordination with the execution of such commands further down the pipeline as well as provides telemetry via the communication layer indicating the state and progress of the sequence.
          
          It is at this point that the two control type pipelines merge where the high and low level commands are translated into ``state drivers''. 
          From an object-oriented software perspective, a state driver instance contained the required signal data to drive hardware outputs, the aggression with which to drive the signal output towards the setpoint signals (referred to as the ``velocity'') and enriching data such as the duration of the signal and the period before which the command sequencer is notified of the command having been completed, useful when the transition to the new signal setpoint did not match the duration of the hardware effect.
          
          Figure~\ref{fig:softDesign-cmdTranslationFlow} omits a step between the command translator and the state driver executor responsible for managing the timing of the state drivers, namely the dispatcher. The dispatch step assesses the data in the state driver and if no timing detail is included, dispatches the signal driver to the state/control loop immediately. If timing data is present and the state driver contains signals which are to be effected only for a specified duration, the state driver is sent to the state driver executor which will record the state of the hardware signals prior to driving the signals. Once the new signals are effected for the specified duration, the state driver executor drives the originally recorded signals so as to return the hardware to the previous states.
          
          The final step in the pipeline is the state loop (also referred to as the control loop). Signal drivers contained the desired setpoints of the hardware and the velocity, which is not to be confused with signal duration. Therefore, a loop was required to interpolate between start and end signal values in real time, which was implemented by means of an interval operation taking the setpoints and the duration of the setpoint having remained the same and using these details to calculate the resulting hardware signal output. Another feature was included in the state loop which allowed specification of the interpolation curve or timing function. As such, a timing function property was included in the state driver object allowing this specification to be passed from command to state loop. Allowing the system to specify a timing function presented a simple method to effect fluid motion of the servos thus preventing damage to the servo mounts, horns, gears and the wheels themselves. It was at this point that, in the case of an obstacle warning from the proximity subsystem or an emergency shutdown, all hardware control could be blocked for safety. The signals are passed through a manipulation block used to provide servo trim configuration (separate from the offset configuration exposed by J5) and output modifiers, functions to modify the signal due to hardware characteristics, after which the hardware abstraction layer is utilised to effect signals.
          
          For hardware other than the servos, the translation performed in the command translator block used the relevant hardware abstraction API instead of invoking the signal dispatcher, as seen in Figure~\ref{fig:softDesign-cmdTranslationFlow}.
          
        \subheading{Communication Transport Layer} \\\\
           All three servers interfaced with the wireless module by default (an operating system level interface). A common pattern that was carried across from this software component to the RSVP Server and Client was the pairing of WebSocket server modules with an accompanying translator module. The endpoint-translator structure and interface is discussed in more detail in Section~\ref{subsec:commonSoftwareComponentDesign}. It can be seen in Figure~\ref{fig:softDesign-rceStructurePlan} that each part of the communication layer is exposed to the sequencing block, allowing them to be initialised and configured during a sequence as well as allowing for sequences to be triggered in an event-driven fashion. The RCEIO server was designed to handle message data of both control and telemetry types. It was decided that the implementation of RCEIO be a server endpoint and not a client endpoint so that the connection process on the RCE side remained as static as possible (i.e. requiring little configuration and logic). This left much of the network resolving and connection procedure up to the RSVP Server, a software component far more accessible to an operator if such access was required.
           
           It was decided that the streaming instance remain separate from the data communication since the choice of WebRTC as the media streaming technology. However, after small-scale proof of concept development and tests, it was found that WebRTC, including but not specifically Kurento, were tools more suited to a web browser environment. WebRTC primarily makes use of the browser-camera interface provided by browser vendors and fair but above-par support for a Node.js environment for anything other than the server. The RCE required a lower level of control for the web camera and this included the process of obtaining video data from it. As such, an approach rawer in operation to that of a WebRTC endpoint was to use a Linux tool which streamed a compressed but mostly unaltered feed directly from the camera, of which there were many as discussed in Section~\ref{sec:softwareDevelopment}, and did so by means of a Real Time Streaming Protocol (RTSP) server to which another entity on the network would connect on a separate port. As shown in Figure~\ref{fig:softDesign-commStreamingDesign}, the Node.js RCE process (in the Linux operating system sense of the word) spawns a new process, referred to as a ``child process'', which would invoke the streaming server tool and essentially run parallel to the RCE. This was beneficial to the design in that video streaming operations would not block the execution of operations as part of the RCE which would have negatively impacted critical functionality such as the carrying out of hardware control.
           
           \begin{figure}[h!]
             \centering
             \includegraphics[width=0.6\linewidth]{figures/softDesign-commStreamingDesign}
             \caption[Diagram showing the spawning and interaction of a separate streaming process by the RCE.]{Diagram showing the spawning and interaction of a separate streaming process by the RCE.}
             \label{fig:softDesign-commStreamingDesign}
           \end{figure}

    \subsubsection{RSVP Server Design}
    \label{subsubsec:rsvpServersPlan}
      \subheading{Plan of Structure}\\\\
        The RSVP Server was simpler in functional composition as it primarily handled communication. As with the RCE design, the Server consisted of the Node.js platform and entry point and a system module which maintained the operation of the rest of the subcomponents. The Server consisted of four server endpoints, one of which was an HTTP server and the rest WebSockets, and one WebSocket client. All of the servers as well as the client-endpoint operated over the network interface provided by the Node.js runtime. The same data store structure used for the RCE was present in the Server design for state data and telemetry. Additionally, a connected client management module was added to the design to manage RSVP Clients in terms of their access to various parts of the system.
        
        The Kurento Media Server is included in Figure~\ref{fig:softDesign-serverStructurePlan} despite it being a separate system process on the host operating system. The interface between this Media Server and the RSVP Server is discussed below.
      
        \begin{figure}[h!]
          \centering
          \includegraphics[width=1\linewidth]{figures/softDesign-serverStructurePlan}
          \caption[Block diagram of the designed software structure for the RSVP Server.]{Block diagram of the designed software structure for the RSVP Server.}
          \label{fig:softDesign-serverStructurePlan}
        \end{figure}

        \subheading{RCEIOClient}\\\\      
          The RCEIOClient Websocket client-type endpoint served as the single message data communication link between the Server and the RCE, and as such, catered for control (uplink) and telemetry (primarily downlink) data. The RCEIOClient translator module routed incoming messages between the two Client-Server WebSocket channels where appropriate or stored incoming data in the data store. Conversely, messages from the two Client-Server channels intended for the RCE converged via the translator.

        \subheading{ControlIO and TeleIO}\\\\
          Communication between the RSVP Server and connected RSVP Clients was split between two WebSocket channels, the first being ControlIO. This channel was responsible for transmission of commands and control signals from the Client to the RCE, thus resulting in communication primarily in the uplink direction. Additional messages such as indication of the type control in use were communicated via this channel. Making this channel separate made it easier to securely restrict the rover control access to only one RSVP Client instance, managed by the connected client management system as discussed below. Software semantics played a part in this design choice as well.
          
          The TeleIO client channel was used for all telemetry data from either the RCE (although not connected, via RCEIOClient), Server or the Client.

        \subheading{Client Management}\\\\         
          The requirement for the control of the rover to be suitable in an educational environment or in places where many users might want to gain control created the need for management of the RSVP Client instances, specifically their allowed level of control. As such, the connected client management system was included in the Server design and utilised Socket.io's exposure of the list of connections on a particular channel. Although only one Client would have access to control communication at one time, all Clients were connected to the ControlIO channel and thus the management system used the list of Clients, each identified by a random, Socket.io-generated string ID, to keep track of disconnecting and connecting Clients. A proxy was built into the ControlIO pipeline which allowed the management system to block any attempted control communication from a Client whose ID did not match the ID of the Client allowed access.
          
          For the purpose of this project, the basis upon which Clients were granted access to rover control encompassed the first-come first-serve principle. This meant that Clients were required to request access for control in which case their ControlIO connection ID was inserted into a queue and once the ID reached the top, access was given (with notification thereof). The Client remained in control until disconnection or if they Client opted to relinquish access. However, the system was designed to be flexible and implementing other principles of scheduling control access could be achieved with ease requiring only a change of logic in the manipulation of the queue or at the point of proxy in ControlIO.
          
        \subheading{Kurento and Media Broadcasting}\\\\
          The RSVP Server was responsible for the majority of the video broadcasting pipeline and thus the Kurento implementation made up a large part of the design. As discussed in previous sections, the RCE streamed the video via an RTSP connection to obtain the raw video data. The data was then passed into the implementation of the Kurento framework where it was streamed to the connected RSVP Clients via the Kurento Media Server. Figure~\ref{fig:softDesign-serverSideKurento} shows the relationships between each of the components involved in the video streaming mechanism from the RCE to the point at which RSVP Client instances connected to receive the broadcast. The diagram makes clear the difference in function of the KurentoIO WebSocket server and the Kurento Media Server. A key detail in the designed implementation of the broadcasting system was the fact that the Media Server ran as a separate process, as it was, in fact, a separate utility altogether. The intention behind bringing an intermediate server into the peer-to-peer principle of WebRTC communication was to improve on multimedia streaming and calling in areas such as multi-client broadcast which was a significant advantage for the nature of this project, transcoding multimedia (and the ability to offer multiple types of the same broadcast source to various different clients), recording, mixing and many other features \cite{kurentoDocsMediaServer_2016}. In the context of the RSVP Server, the KurentoIO subcomponent coordinated incoming ``calls'' or requested connections from Client instances via its WebSocket endpoint which was easily accessible by the Clients over the network. This method of communication was utilised throughout the connection negotiation process whereby the client initiates such a negotiation with an SDP offer making the Kurento mechanism component of KurentoIO aware of the type and shape of the Client concerned. The Server responds to the offer made and this cues the Client to send multiple ICE candidates each describing supported multimedia capabilities of the Client system as well as available transport mechanisms. The Server does the same and when a pair of ICE candidates agree, the connection is established. At the same time, communication is made with the Media Server process by means of yet another WebSocket connection along which the Kurento Protocol (JSON-RPC) is used to offload the connection established onto the Media Server. From this point onwards, the RSVP Client communicates directly with the Media Server. Network change negotiations as well as disconnection procedures are also performed on the KurentoIO connection.
          
          \begin{figure}
            \centering
            \includegraphics[width=0.8\linewidth]{figures/softDesign-serverSideKurento}
            \caption[Diagram of the server-side relationships with the video stream components in the RCE-RSVP system.]{Diagram of the server-side relationships with the video stream components in the RCE-RSVP system.}
            \label{fig:softDesign-serverSideKurento}
          \end{figure}
          
          
    \subsubsection{RSVP Client Design}
      \subheading{Plan of Structure}\\\\
        The RSVP Client was a tightly integrated blend of static front-end components and JavaScript modules to turn the web view into a fully functional and responsive SPA. Figure~\ref{fig:softDesign-clientStructurePlan} shows the Client application code served from the RSVP Server as well as the WebSocket client-translator pairs for the discussed channels of communication including the implementation of the client-side Kurento library. The large development portion of this software component was the UI (user interface) which will make up the majority of this subsection.
        
        \begin{figure}[h!]
          \centering
          \includegraphics[width=1\linewidth]{figures/softDesign-clientStructurePlan}
          \caption[Block diagram of the designed software structure for the RSVP Server.]{Block diagram of the designed software structure for the RSVP Server.}
          \label{fig:softDesign-clientStructurePlan}
        \end{figure}
        
      \subheading{Layout Overview}\\\\
        The style of layout of the UI at the highest level was in accordance with Google's Material Design specifications for applications, and consisted of an application content area with a swipeable menu panel on the left hand side. It was decided that two screens were to be developed, each one for each of the control styles. Prior to development of the UI using the technologies discussed, the two screens, menu panel, and each of the components in each of the screens were sketched to verify the validity of the layout and to ensure consistency of design throughout the development process, one prone to drift in style and design over time.
        
        Figure~\ref{fig:softDesign-rsvpClientLayoutOverview} shows the general layout plan of each of the two screens as well as the mobile equivalents. The project specifications indicated the requirement for the application to be mobile compatible, thus included in every design stage made in the desktop environment was a plan of the mobile version of that particular stage.
        
        \begin{figure}[h!]
        \centering
        \subfloat[Interactive control mode.]{
          \includegraphics[width=1\linewidth]{figures/softDesign-rsvpClientLayoutOverview-Interactive.pdf}
        } \qquad
        \subfloat[RoSE control mode.]{
          \includegraphics[width=1\linewidth]{figures/softDesign-rsvpClientLayoutOverview-RoSE.pdf}
        }
        \caption[Layout plan of the RSVP Client User Interface for both methods of control.]{Layout plan of the RSVP Client User Interface for both methods of control.}
        \label{fig:softDesign-rsvpClientLayoutOverview}
        \end{figure}             
        
        Each of the UI components shown in Figure~\ref{fig:softDesign-rsvpClientLayoutOverview} are discussed below.
        
      \subheading{Video Stream Component}\\\\
        The stream section of the UI was designed to be simply a container element for the HTML video element which was to be attached to the Kurento framework instance. During page load, an internal JavaScript module reaches into the DOM and returns the \mintinline{js}{video} element to the Kurento framework, which handles displaying the received video stream in it.
              
      \subheading{Rover Controls (Interactive)}\\\\
        The rover controls component, a mockup of which is included as Figure~\ref{fig:softDesign-controlUIComponentDesign}, was split into two sections, each positioned on the left- and right-hand bottom corners of the content area of both the desktop and mobile configurations. The left hand subcomponent holds the controls for rover traversal, which consist of an interactive two-dimensional joystick and two buttons for rotating the rover about it's central axis. The $y$-axis of the joystick controls the forwards and reverse velocity of the rover and the $x$-axis of the joystick controls the amount by which the rover will turn given some component of forwards or reverse velocity (in other words, the amount by which the wheels are rotated along the steering axis). The right component controls the angular position of the head about its pan and pitch axes and is sticky in behaviour allowing the user to position the head and have it remain in that position. A button above the head joystick allows the user to center the head upon pressing it.
      
        \begin{figure}[h!]
          \centering
          \includegraphics[width=0.8\linewidth]{figures/softDesign-controlsUIComponentDesign}
          \caption[Diagrammatic mockup of the interactive control component of the UI.]{Diagrammatic mockup of the interactive controls component of the UI.}
          \label{fig:softDesign-controlUIComponentDesign}
        \end{figure}
        
        \subheading{Rover Overview Component}\\\\
          The rover overview component of the UI was designed to be a highly engaging graphical representation of the rover as a means of displaying telemetry from the rover's control software subcomponents. The design of the rover did not include feedback sensory hardware, thus the data used in this overview element was that of the signals used to drive the hardware. The data still gives an accurate estimation of the hardware state of the rover. The component consisted of an SVG graphic of the top view of the rover with wheels and a head that could dynamically rotate in-view. Included in the graphic were indicators for the proximity sensor data including whether or not they were triggering proximity/obstacle warnings. On either side of the component, sections for each of the hardware components displayed textual telemetry of their state, as seen in the mockup in Figure~\ref{fig:softDesign-roverOverviewUIComponentDesign}. The overview component was placed in the usable space (as in Figure~\ref{fig:softDesign-controlUIComponentDesign}) between both control element sections.
        
          \begin{figure}[h!]
            \centering
            \includegraphics[width=0.7\linewidth]{figures/softDesign-roverOverviewUIComponentDesign}
            \caption[Diagrammatic mockup of the rover overview component of the UI.]{Diagrammatic mockup of the rover overview component of the UI.}
            \label{fig:softDesign-roverOverviewUIComponentDesign}
          \end{figure}
        
      \subheading{Rover Sequence Editor Component}\\\\
        The RoSE component replaced the rover controls component when switching from the interactive style of control to the RoSE style. The component was designed to allow the user to compose a sequence of commands, view and edit the sequence and transmit the sequence to the rover for execution. Further, the component included controls for the control of execution of the sequence as well as reported back the status and progress of the sequence execution.
        
        Figure~\ref{fig:softDesign-sequenceEditorUIComponentDesign} shows the list of command items in the main area of the component. A new command could be created by clicking on the ``plus'' icon on the bottom bar section of the component, which would show a dialog box allowing the user to choose which command to create and afterwards a series of controls for entering the parameters of the command. Each command item contained the name of the command and a summary of the parameters that were entered into the new command dialog box. On the left of the command name, an icon showed the type of command (low-level, high-level or macro) and on the far right of the item an edit button to bring up the dialog box to edit the parameters of the command and a delete button to remove the command from the sequence. The items in the list could be reordered by dragging the item to a new location in the sequence.
        
        \begin{figure}[h!]
          \centering
          \includegraphics[width=1\linewidth]{figures/softDesign-sequenceEditorUIComponentDesign}
          \caption[Diagrammatic mockup of the RoSE-style sequence editor component of the UI.]{Diagrammatic mockup of the RoSE-style sequence editor component of the UI.}
          \label{fig:softDesign-sequenceEditorUIComponentDesign}
        \end{figure}        
        
        The sequence may be uploaded when complete, and executed if the RCE acknowledged the new sequence. The controls for uploading and controlling the execution of the uploaded sequence were placed on the right hand side of the bottom bar section. To simulate the strict procedure when creating, editing and executing sequences on the RSVP for \textit{Curiosity}, the sequence editor component only allowed the sequence to be executed if all new changes had been uploaded and disallowed editing if a sequence was uploaded until the edit button on the left hand side of the bottom bar section was pressed to put the component back into editing mode.
        
        During execution, the RCE indicated the command that was being executed in real time and the sequence editor component highlighted that command to show the user the progress of execution.
        
      \subheading{RCE System View}\\\\
        To the left of the video stream container in the desktop layout (for both interactive and RoSE control configurations shown in Figure~\ref{fig:softDesign-clientStructurePlan}) was a tabbed view which contained two views, one of which was the RCE system view component. Telemetry related to the RCE system itself and various subsystem status data was shown in this view. The top section of the view consisted of four dial components to show the CPU and RAM usage of both the RCE Node.js process and the separate video stream utility process as discussed in Section~\ref{subsubsec:softDesign-rceDesign}. Below the dials was a list of the hardware control software components showing the initialisation and online status of each. Figure~\ref{fig:softDesign-rceSystemViewUIComponentDesign} shows the component design detail.
        
        \begin{figure}[h!]
          \centering
          \includegraphics[width=0.75\linewidth]{figures/softDesign-rceSystemViewUIComponentDesign}
          \caption[Diagrammatic mockup of the RCE system view component of tabbed telemetry container in the UI.]{Diagrammatic mockup of the RCE system view component of tabbed telemetry container in the UI.}
          \label{fig:softDesign-rceSystemViewUIComponentDesign}
        \end{figure}        
        
      \subheading{Server Status View}\\\\
        The server status view was another page in the tabbed view as used for the RCE system view. This component was similar to the RCE system view, however, it showed data related to the RSVP Server. This was designed to give the user more insight into the real time operation of the server as well as be a helpful tool in the monitoring of the server for maintainers of the RSVP system.
        
        The server status view consisted of the status of the server instance, that of the Kurento Media Server instance as well as how many RSVP Client instances were connected to the server at that point in time.
        
      \subheading{Menu Component}\\\\
        As mentioned, the application included a side panel that was designed to serve as a menu. Since the application did not require many pages or views, the menu was more functional than navigational, a classic menu use case. The menu allowed the user to perform the following operations:
        
        \begin{itemize}
          \item \textbf{Start Stream:} The ``Start Stream'' button allowed the user to initiate the WebRTC call in an attempt to begin to receive the video stream. When the application was initially loaded, the stream started automatically. In the event that that user decided to stop the stream, or the stream disconnected due to a network error, the user could make use of this button to resume the stream.
          \item \textbf{Request Control:} The ``Request Control'' button allowed the user to place their instance of the RSVP Client in the queue to gain access to control of the rover.
          \item \textbf{Control Dropdown:} The ``Control'' dropdown element revealed two controls related to the style of control in use. The first control was a switch element which switched the control style between ``interactive'' and ``RoSE''. The second control allowed the user to select the level of difficulty of the simulation of control.
          \item \textbf{Settings Dropdown:} The ``Settings'' dropdown element revealed a set of settings controls which included:
          \begin{itemize}
            \item RCE endpoint detail configuration (IP address)
            \item a button to open the trim edit dialog
            \item a button to reset the RCE if required (and the user has access to this command)
          \end{itemize}
        \end{itemize}
      
    \subsubsection{Common Software Components Design}
    \label{subsec:commonSoftwareComponentDesign}
      Developing the full-stack in JavaScript meant that many of the subcomponents and features could share design patterns, technology choices and code implementations without the abruptness of having to design for differing language and/or platforms. It was quickly identified that many of these subcomponents were required in all three of the software components and as such, are discussed in this section.
      
      \subheading{Synchronised Data Store}\\\\
        During the design process for each of the software components, the need for a mechanism to reliably store global state data was realised. Operations across all modules within each of the components relied on the state of many other modules and thus a well designed central store for this state data was recognised as being beneficial to the design. More importantly, however, was the need for the communication of this state data between each of the components. An example of such was the need for the RSVP Server to be aware of the initialisation status of the camera on the rover. Once the camera was initialised, that state change was required to be communicated across the network to indicate to the RSVP Server to initiate a connection with the camera streaming port on the RCE and to offer the stream to the Kurento Media Server.
        
        A further important detail in the data store requirement was for it to be asynchronously notifying. The nature of Node.js and JavaScript in the browser was one that was event-driven and this applied to data changes as well. The alternative to having event-based data change notifications was for points in the software components that require knowledge of changes in data to poll the central store of data at some predefined frequency and compare the data in search of differences. Since Node.js is single threaded, this would have had significantly negative impacts on the performance of the software components, especially in the context of this project where state data was prevalent.
        
        The opportunity to use the data store module for easy telemetric broadcast was also recognised during the design process. Data in the form of telemetry was able to be saved to the store and the configuration of the store structure would determine the channels along which such data would be broadcast, all of which would happen asynchronously.
        
        Operations that were required from the data store API included the ability to:
        \begin{itemize}
          \item set data,
          \item read data,
          \item register callback functions that would be executed upon the change of data at a particular path (i.e. listen to data changes),
          \item listen to data changes at any level below a particular path in the data structure,
          \item specify whether or not the data at a particular path was to be broadcast over a chosen WebSocket channel upon change,
          \item receive data from store event emitters on other software components, across the network,
          \item request that already existing data be broadcast from one software component to another, and
          \item re-notify all appropriate listeners and WebSocket channel clients of already existing data.
        \end{itemize}
        
        The module was designed to include a data store class definition which incorporated the required methods and event emitter features to provide the required functionality. For each of the software components, classes were instantiated with the required fields and notification channels and exposed to the rest of the modules in each system. Figure~\ref{fig:softDesign-dataStoreStructureNormal} shows the internal structure of one such data store and the use of the API in a typical read, set and notify scenario.
        
        \begin{figure}[h!]
          \centering
          \includegraphics[width=0.8\linewidth]{figures/softDesign-dataStoreStructureNormal}
          \caption[Diagram showing a functional sequence of typical interface between a data store instance and application code.]{Diagram showing a functional sequence of typical interface between a data store instance and application code.}
          \label{fig:softDesign-dataStoreStructureNormal}
        \end{figure}
        
        Software component A and in Figure~\ref{fig:softDesign-dataStoreStructureNormal} could each be either of the RCE, RSVP Server or RSVP Client software components. Component A creates a listener on a particular path's change of data with an associated callback function. Code elsewhere in the component sets new data to the store at that path at point \textbf{1} using the data store's \mintinline{js}{set} API method. This triggers an event to be fired which matches that of the listener registered previously, and thus the new data event reaches the listener at point \textbf{2} as well as the callback function is executed at point \textbf{3}. At the same time, a notification of the data change is broadcast to software component B via the configured WebSocket channel (which in this case could be either RCEIO, ControlIO or TeleIO) at point \textbf{4}. The same flow of operations would apply to the case where an change notification was received from software component B, in which case the callback function would be fired after having the data be received and ``set'' internally.
        
        \begin{figure}[h!]
          \centering
          \includegraphics[width=0.8\linewidth]{figures/softDesign-dataStoreStructureRepushRequest}
          \caption[Diagram showing a functional sequence of a request for a repush of data from a remote data store.]{Diagram showing a functional sequence of a request for a repush of data from a remote data store.}
          \label{fig:softDesign-dataStoreStructureRepushRequest}
        \end{figure}        
        
        Figure~\ref{fig:softDesign-dataStoreStructureRepushRequest} shows the flow of operations in the event that the application code of software component A requests that software component B resends (repush's) all data at a particular path (point \textbf{1}). The request is sent to component B via a WebSocket channel at point \textbf{2} and the component repushes the data at point \textbf{3} making use of its data store's \mintinline{js}{repush} API method. The same process of the event reaching the listener and the callback being executed applies as in the first example. Requesting data was particularly useful when one or more of the software components had to be restarted and required resynchronisation of its data with the already online software components.
        
      
      \subheading{WebSocket Design}\\\\
        As described, the WebSocket implementations comprised of the server/client endpoint (the instance of Socket.io) and a second module, named the translator, which served as a handler of incoming and outgoing messages. Since there were many WebSocket connections and hence subcomponents, a naming convention was introduced where the name of the endpoint subcomponent was formulated by \mintinline{js}{<subject>IO} and \mintinline{js}{Client} was appended if the endpoint was to connect to an already existing WebSocket server. Further, \mintinline{js}{Translator} was appended to the translator half of the WebSocket implementation. Figure~\ref{fig:softDesign-webSocketDesign} shows the designed interface between the WebSocket implementation subcomponents and the RCE.
        
        \begin{figure}[h!]
          \centering
          \includegraphics[width=0.75\linewidth]{figures/softDesign-webSocketDesign}
          \caption[Diagram showing the interface with and structure of the Socket.io-translator module pair.]{Diagram showing the interface with and structure of the Socket.io-translator module pair.}
          \label{fig:softDesign-webSocketDesign}
        \end{figure}
        
        A simple mapping of incoming message events and outgoing message methods was made between the Socket.io instance and the translator. On incoming messages, the translator decides the correct behaviour based on the type of message as well as, in some cases, data sent with the message. The translator also exposes an API which can be used as convenience methods to send standard types of messages. This relieves application code having to package the message and payload when sending such a message, which could have also become a point of weakness in case of programmatic errors or change in design. Data change events from data stores are also fed into the translator to notify other software components.
                
           